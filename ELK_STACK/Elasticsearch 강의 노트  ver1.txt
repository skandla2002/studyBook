Elastic Engineer

참고 사항: 
https://elastic.co/support/eol : 제품 단종일
https://elastic.co/blog/ : 기술적 내용 공식 블로그
https://elastic.co/guide/index.html : 모든 기능

------------------------------------------------------------------
1. Elasticsearch Fundamentals
------------------------------------------------------------------
(1) 역사
1999년의 Lucene ->
    (장점) Search Engine Library(저장이 아닌 검색 엔진용) 양이 많아도 검색이 느리지 않음
    (단점) Lucene 라이브러리가 사용하기 어려움, standard-alone 기준으로 만들어서 스케일업이 어려움
2004년에 Lucene을 기반으로 한 인터페이스 솔루션 상품 제작(Compass 프로젝트)
2010년에 scalability(규모 가변적)에 대해 주요 쟁점화하여, Elasticsearch로 이름 바꿈
  - 멀티 language 지원: REST API 사용으로 Client의 언어와 무관
  - scalability 가능: cluster단위로 일함: 안에 node 몇개인지 구별할 필요가 없음
현재 검색 엔진 순위: Elastic > Splunk > Solr

(2) 개요
1) 사용 용도 : 로깅, metrics, business analytics, security analytics 등
2) ELK Stack : Beats(수집) > Logstash(수집 / 전처리) > Elasticsearch(저장 / 검색 / 분석) > Kibana(시각화)
3) 사용 방법: Standalone, Elastic Cloud Enterprise, Elastic Cloud (SaaS)

(3) 상세
1) 분산 검색 : 수평적 스케일업이 가능한 구조임 - 기본 1 to 1 (일반적으로 1개 node당 1개 서버로 사용)
              검색은 1개의 Cluster 기준으로 처리(Cluster는 1개 node 이상으로 구성[master nodes, ingest nodes, data nodes-hot, data nodes-warm])
2) JSON Objects 처리: 테이블 형태가 아닌 json object 로 사용
3) Document Store: json object 1개 - data 폴더 안에 document가 저장됨(각 document는 1개의 cluster 안에서 Unique ID 값 가짐)
4) 최초 설치 및 동작:
 - www.elastic.co/downloads/elasticsearch : 릴리즈 버전 파일(설치파일)
   https://github.com/elastic/elasticsearch : 소스 형상
 - JRE / JDK 사전 설치 필요 : JAVA_HOME에 설정(단 Elasticsearch 7.x 에서는 java도 함께 다운 로드됨, JAVA 8 필요, https://www.elastic.co/support/matrix#matrix_jvm 참고)
 - 경로 정보
   bin: 실행 파일 / plugin
   config : elasticsearch.yml 파일          : ES_PATH_CONF
   data   : 인덱스와 공유 node에 대한 데이터  : path.data
   jdk    : java vm                        : JAVA_HOME
   lib    : elk 관련 library
   logs   : 로그 파일(클러스터 명으로 생성)   : path.logs
   modules: Elasticsearch modules
   plugins: 플러그인 설치 경로 
 - 주요 configuration files:
   elasticsearch.yml - 주요 설정
   jvm.options       - heap 할당에 대한 정보 (예시: -Xms1g -Xmx1g )
   log4j.properties  - log 정보
 - properties 설정
   1) config file을 직접 수정 
   2) command line에서 수정 : ./bin/elasticsearch -E path.data=/data/elastic/elasticsearch
                             ES_JAVA_OPTS="-Xms512m" ./bin/elasticsearch
 - 동작
   1) 시작(elasticsearch 실행): 추가: ex] ./bin/elasticsearch -d -E node.name=node1 -p es.pid
                                    -d -p elastic.pid : -d (백그라운드 실행), -p (pid를 찍음[kill 할때 사용])
   2) Node : elastic instance 1개(JVM 위에 띄움), 서버 하나에 1개 노드(1-to-1 으로 불림)
   3) Node Name : unique id  자동 UUID 생성됨(node.name / .yml 파일에서 변경 가능)
                  ex) node.name: ACMEES001 [':'를 기준으로 붙이기 / 띄워쓰기 확인하기]
   4) Stop Node: Ctrl + c / kill `cat elastic.pid` 
   5) logstash 나 filebeat 실행: 
     - ./logstash-7.3.1/bin/logstash -f datasets/blogs_sql.conf
     - ./filebeat-7.3.1-linux-x86_64/filebeat -c datasets/filebeat.yml

(4) 추가 설명
 - Cluster: node 생기면 자동생성(클러스터는 노드 1개 부터 여러개 가능(노드는 1-to-1을 일반적 사용)
   cluster.name: prodcluster
 - log 파일: logs 폴더 안에 clustor 명으로 log가 찍힘 
            -rw-rw-r-- 1 elastic elastic 19267 Dec  9 01:48 elasticsearch.log					
 - Document를 하나 저장한다.(cluster)
   : cluster에 index(table과 비슷하지만 같지 않은, 논리적인 개념임[물리적 개념아님])라는 저장 공간에 파일을 indexing(document를 cluster 안에 저장하는 행위)함
 - Index a Document : Index API는 PUT / POST를 이용한다.
                      PUSH은 documentID를 찍어서 넣고, POST는 documentID를 지정하지 않고 elastic엔진지 자동 생성함
                      curl -X PUT "localhost:9200/my_blogs/_doc/1" -H 'Content-Type: application/JSON' -d
                                                 /인덱스name/document endpoint/documentID
 - Console: Kibana는 DevTools에서 테스트 해볼 수 있음
 - The Resopnse 확인 사항 
   : httpstatus : 201 response 확인
     ID: _id
	  Document: _version
 - Elasticsearch는 PUT 계속 사용시 insert후 다음번 호출시 update 함(_doc 사용시)
   : PUT my_blogs/_create/1 => 호출시 처음은 insert하고 이후 error 발생
   : _update => 호출시는 처음 insert하지 않고, 있어야지만 update함
   : DELETE my_blogs/_doc/1 : 200이면 document 삭제함
 - Bulk API: (create / index / update / delete 호출)을 1번으로 호출함
   : POST comments/_bulk
      {"index" : {"_id":3}},
	   {"update" : ... },
	   {"delete" : ...}
 - Retrieving a Document: GET my_blogs/_doc/1 - _source안이 우리가 넣어준 raw data
 - CRUD Operations:
   Index(POST/PUT은 _doc), Create(PUT은_create), Read(GET은_doc), Update(POST는_update), Delete(DELETE는_doc)
 - 엘라스틱서치에서 처리 DATA
   Dataset: Static Data vs Time Series Data 처리 - 양쪽 모두 적용 가능함
   형태 1. static Dataset: Elastic blog 글(RDBMS에 있는 것)
   형태 2. Time Series Dataset: elastic.co/blog의 access log를 이용
 - kibana는 auto refresh로 사용 가능(대시보드처럼 초단위 refresh 사용가능)
 - Search
   : queries(검색) 와 aggregations(분석 통계 지표, ex)남성이 구매한 총액 / 여성이 구매한 총액 )
 - response: quertis 는 hits
             aggregations는 buckets
      ex) GET my_blogs/_search : took는 얼마나 걸렸는지(milliseconds)
          GET logs_server1,logs_server2/_search
	       GET logs_server*/_search
 - 기본적인 검색 요청의 경우 최초 10개만 리턴함(설정으로 변경은 가능함)
 - logstash 를 실행해서 사용함
   input / filter / output을 이용함
   input {
      jdbc {
         jdbc_connection_string => "jdbc:postgresql://db_server:5432/"
         jdbc_driver_class => "org.postgresql.Driver"
         jdbc_driver_library => "/home/elastic/postgresql-9.1-901-1.jdbc4.jar"
         jdbc_user => "postgres"
         jdbc_password => "password"
         statement => "SELECT * from blogs" // 한 row가 document 화 됨
         }
      }

      filter {
         mutate {
            remove_field => ["@version", "host", "message", "@timestamp", "id", "tags"]
         }
      }

      output {
         stdout { codec => "dots"}  // 실행될때 '.'을 찍음
         elasticsearch {
            index => "blogs"
         }
      }




------------------------------------------------------------------
2. Elasticsearch Queries
------------------------------------------------------------------

relevant 
  찾을것을 다 가져왔는냐(Recall)
  찾아온것 중에 내가 원한것이 얼마나 되느냐(Precision)
  => Ranking 함
  

GET blogs/_search
{
	"query": {
		"match": {
			"content": "ingest nodes"
		}
	}
}
=> 너무 많이 나옴, ' '는 or 조건임

7.0 이상을 10000개 이상이면 relation 값이 gte로 추가되고 value는 10000이 찍힘(이하면 relation이 eq 임)
 => "track_total_hits": true - 정확한값 필요할때
 
GET blogs/_search
{
	"query": {
		"match": {
			"content": "ingest nodes"
			"operator": "and"
		}
	}
}


term이 3개 일때

GET blogs/_search
{
	"query": {
		"match": {
			"content": "ingest nodes logstash"
		}
	}
}

=>

GET blogs/_search
{
	"query": {
		"match": {
			"content": "ingest nodes logstash",
			"minimum_should_match": 2 // 3중에 2개만 match 문서
		}
	}
}


 TF(term frequency) - 예를 들면 the 값은 경우는 많이 나오지만 불필요함(field 별로 계산)
 IDF(inverse document frequency) - 짧은 문장안에서 너무 자주 나오는 단어면 중요도를 높인다.(index 전체에서 계산)
 Field length
 => 현재 elasticSearch의 Sroce는 위를 개선하여 BM25 알고리즘 사용함 
 
 match query에서 relevance 높이기 위해서는 'AND'가 무조건 사용해야하는 것은 아니다.
 precision을 높이기 위해서는 match에서 minimum_should_match를 사용한다.
 TF는 5번 넘어가면 그다음 값은 비슷해짐
 
 => elastic relevance 검색 => 사용 알고리즘을 변경 할 수 있다.(script나 index 하위 similarity를 가지고 선정 할 수 있음) 
   : index-modules-similarity.html 문서를 참조한다.
   : 하지만 기존 field에 대해서는 새로 색인 해야함(신규 field는 새로 색인 안해도 됨)
     => 단 외부에서 접속할때는 alias를 이용해야 field가 변경되어도 처리 할 수 있음


Searching for phrases: 
 match_phrase Query
 Another Example: 
  the slop parameter - 2단어로 그물을 넓히거나 줄일 수 있음
  pre-field Boosting - 제목에서 score를 더 주게됨
    "title" -> "title^2" 로 변경함(부스트)
  boost를 잘하는 법
    - it depends(author는 큰 의미 없음)
	- 각자의 데이터에 맞는 것을 작성해야함
 "type": "phrase"로 match를 사용하지 않고, match_phrase를 사용함
 
 Mispell Words : 오타 찾기
  - fuzziness를 사용 가능함 shark - shard 이면 fuzziness 1
                            matche queri - match query 이면 fuzziness 2
							=> 한글의 경우 글 1개에 대해 fuzziness(unicode 기준, 노리 등에 대해서도 쓰고 난 다음 결과로 처리함)
  - misspelling에 대해서 2개의 강의
     : 비용;;;

 Quiz: match(텀 상관 없이 맞춤) match_phrase(텀에 순서 등에 따라 맞춤)
       match_phrase는 slot propertity가 있어야 진행가능함
       monitoring data일때는 어떻게 될지 확인 필요(fuzziness는 auto로 생성할 수도 있음)	   


--------------------------

The bool Query
- Query: must(있어야함) / must_not(없어야 함) / should(있으면 좋다, hits에 영향을 대부분 주지 않지만, 특정 시점[should만 사용할때]에만 영항줌) : 점수계산이 존재함 
- Filter: filter(must 지만 점수 계산을 안함) => 빠름

- Improving Relevancy: 
GET blogs/_search
{
	"query": {
		"bool": 
			"must": [
				{"math": {"title":
				

USE minimum_should_match 사용 가능함
 - "should": [
	{match": {"title": "stack"}}.
	{"match_phrase": ...

Only "should" 이면 여러개중 하나만 match 되면 된다는 형태로 로직 구현됨

A Search Tip for Phrases

---------------

Other Ways Query method (DSL 이외에 사용)
- query string: elastic search 에서 자동 DSL로 전환함
 ex) "query": "admin geoip.city_name:(\"san jose\") host:server1", ...
- Kibana Query Languaget 
- SQL Access: 실제 SQL로 쓸 수 있는 고난이도의 SQL은 작동 안함
 ex) "query": """
		SELECT * FROM blogs
		WHERE publish_date >= CAST('2018-01-01' AS DATETIME)
		LIMIT 5
	"""
 
----------------

1. scriptng을 찾을때 Engineering 카테고리에서만 찾으로고 할때의 Query는
 match와 filter를 bool 쿼리로 연결하기
2. filter는 score 계산 안함
3. title필드의 performance가 있으면 올라가는가?
 
추가: should 등에 대한 것은 순서가 상관 없음

--------
Lesson4. Implementing a Search Page



 Filter
   Filter by a date range 사용 가능함
    - Filter와 Cache를 많이 사용할 수록 성능이좋아짐
    "filter": {
		"range": {
			"publish_date": {
				"gte": "2017-12-01",
				"lt": "2018-0-01"
			}
		}
	}	
   Date Math
    "range": {
		"publish_date":{
			"gte": "now-3M"
		}
	}
   Date Math Expressions
	if now = 2017-10-19T11:56:22
    => 날짜 기준이면 00:00:00 으로 끝남
	
   Searching for Exact Terms
    "match": {
		"category": "Brewing in Beats"
	} // OR 조건으로 3개 나옴
	"match": { "categor.keyword": "Brewing in Beats" } } // category로 저장하면 keyword 에 전처리 없는 문자열 그대로 들어감
    "filter": {
		"match": {
			"category.keyword": "Brewing in Beats"
		}
	} // 성능을 향상 시킬수 있음
	
----------
  Sorting
  
    Soring Result
	"sort": [
		{
			"publish_date": {
				"order": "desc"
			}
		}
	]
	
	여러개 줄 수 도 있음
	"sort": [
		{
			"author.keyword": { // keyword는 꼭 사용해야 java heap에 올라가는 메모리를 줄일수 있음
				"order": "asc"
			}
		},
		{
			"publish_date": {
				"order": "desc"
			}
		}
	]
	
-------------
	Paging
	 // from은 0부터이고 아래 내용은 2page임(하지만 실제 운영파일에 대해서는 from을 쓰지 않는게 좋고, scroll API를 쓰는게 좋음)
	 Paging
	  {
	  "from": 10,
	  "size": 10, ...
	
	 from size가 너무 많으면(10000이 넘어서는 안됨, 설정으로 바꿀수 있으나 메모리 사용량으로 권장하지 않음) error가 발생함
	 => memory의 오버해드가 크므로, scroll에 대해서는 batch처럼 Client에서 구현하도록 하기


    실시간 Data에 대해서 paging 처리는: 
	 
---------------
	Highlighting
	
	"highlight": {
		"fields": {
			"title": {}
		}
	}
	
	커스터마이징	
	"highlight": {
		"fields": {
			"title": {}
		},
		"pre_tags": [{"<es-hit>"],
		"post_tags": [{"</es-hit>"]
	}
	
	
---------
 Quiz
 1. paging 할때 처리는 : from, size
 2. sorted는 score로 결과 리턴하는 것만은 아니다.
 3. "category": ... / "category.keyword": ...
   -> 앞은 공백을 OR로 리턴하는데, 뒤는 keyword에 대한 필드 검색함
   
 문의: match term 쿼리와 keyword 사용하는 쿼리는 같은 것인지요?
       - 분석 안하기때문에 똑같은 리소스 사용하고 결과도 같음
	   highlight는 어디에 나오는지
       - 검색이 되는 컬럼에 대해서 처리 하는 경우가 있음 

------------------------------------------------------------------
3. Elasticsearch Aggregations
------------------------------------------------------------------

 - Metrics / Bucket / Combining Aggregations
 
1. Metrics Aggregations
 - 몇초만에 response time에 대해서는 얼마인지 등 질문 하나당 답변 하나가 나오게 함
  "aggs": {
	"1": {
		"sum": {
			"field": "response_size"
		}
	}
  }
 
 Aggregation Syntax
 
 GET my_index/_search
  "aggs": {  // 메소드명
	"my_aggregation": {  // 변수명
		"AGG_TYPE": {
		...
		}
	}
  }
  
  ex) GET logs_server*/_search
		"aggs": {  // 메소드명
			"total_sum_bytes": {  // 변수명
				"sum": {
					"field": "response_size"
				}
			}
		}
	
	"aggregations": {
		"total_sum_bytes": {
			...
		}
	}
	
	검색이 아니라 aggregations만 쓸때는
	"size": 0 으로 하면 네트워크 점유율 낮추는 장점
	"query"가 있는경우 query 실행 후 남은 결과에 대해서 aggregations 하여 처리함
	- "min", "max", "avg" 는 있지만 "median"은 없음("percentitles" 는 사용 가능)
	- 각 백분위의 값(중간 값 등을 획득 가능)
      "percentiles": {
		"field": "runtime_ms",
		"percents": [
			25,
			50,
		    75
		]
	  }
	- 유니크값 뽑기(HyperLogLog++ 알고리즘 사용, 빨리 결과가 나오지만 정확도가 떨어짐, 경향을 파악하는 경우로 사용 해야함)
	   => 유니크값을 정확히 뽑기 위해서는 별도 개발 필요
		"cardinality": {
			"field": "geoip.country_name.keyword"
		}


Metrics aggregations: min, max, avg, stats사용 가능함
                      percentiles의 median은 50%일때 값을 사용 가능

밀리세컨즈: 1000ms = 1s


2. Bucket Aggregation
 - Metrics Aggregation은 숫자 하나에 대한것을 리턴함
 - Bucket Aggregation는 
 - Bucket은 특정 룰에 맞춰서 document들을 저장함
 ex) "date_hostogram": {
		"field": "@timestamp", // datetime을 기준으로 생성함
		"interval": "day"      // 일별로 bucket를 만듦
	 }
  - histogram Aggregation: 숫자 타입으로 범위 지정 가능함
     "histogram": {
		...
	 }
  - range Aggregation : 범위별로 처리함
    "ranges": [
		{
			"from": 0,
			"to": 200
		},
		...
  - terms Aggregation: DOCUMENT가 많은것 부터 desc로 정렬됨(추가 sorting을 위해서는 order 옵션 추가함)
    "aggs": {
		"country_name_terms": {
			"terms": {
			"field: "geoip.country_name.keyword",
			"size": "5"
  - Bucket Aggregation:
    
  - Bucket Sorting: 
	"date_histogram": {
		"field": "@timestamp",
		"interval": "day",
			"order": {
				"_key": "desc"
			}

------------
Quiz
 처음 버켓 사용시 dynamic 하게 변경됨
 어떤 버켓 Aggregation은 일반적인 ordering을 제외한다.
 "error", "warn", "info", etc에 대해서는 term aggregations 을사용하면 좋다.
 
 "size": 0,
 "query": {
	"range": {
		"publish_date": {
			"gte": "2017-01-01",
			"lt": "2018-01-01"
		}
		...
 "aggr": {
	...
 }
 
 ------------
 
3. Combined Aggregation
 해당 날짜의 기간 등의 질문에 답할 수 있음

 키바나에서 Visualize > table로 생성한 다음 > inspector > request 를 보면 DSL로 표현되어 확인 할 수 있음 
 
 sub-Bucket을 사용 할 수 있음: 날짜별 bucket를 만들고 terms에 aggregations 처리하기
 
 Motivation for top_hits Aggregation
  -> 버켓별로 나눠서 할 수 도 있음
 Significant Aggregation: Terms Aggregation + Noise Filter
    - 추천이나 부정행위 탐지 / 결함 탐지에 사용
   "aggs": {
		"author_buckets": {
			
     => 자주 있는 것중에 의미있는 것을 알고 싶다(in, to, the 말고)
	"significant_text": { ...}
	를 이용하면, 다른 블로거도 함께 많은 것은 제외한 결과 값을 뽑음
	  - text / keyword 에 따라서 : significant_text / significant_keyword 두가지
	   => sampler aggregation 은 특성만 확인 할때 사용함(속도 빠르고, 메모리 사용량 적음)
	      -> 정말 정확한 값을 위해서라면 scroll api를 통해서 고객이 직접 개발해야함

Quiz
1. SLA을 만족하지 않는 날은 몇일인가(95%, 500ms 이하)
 - percentiles aggregation
2. 얼마나 많은 코드들이 requests가 날별로 발생했나
 - terms aggregation
3. 
	
추가: Term aggregation 으로 검색하면 여러가지가 나옴(pipeline aggregation)
추가: size가 0이 아니면 fatch phase[각서버에 호출한 다음 그에대한 쿼리 결과를 리턴해 주므로] 단계를 줄일수 있으므로 성능 향상이 될 수 있음


------------------------------------------------------------------
4. Elasticsearch Text Analysis and Mappings
------------------------------------------------------------------
------------------------------------------------------------------
5. Elasticsearch Nodes and Shards
------------------------------------------------------------------
------------------------------------------------------------------
6. Elasticsearch Monitoring and Troubleshooting
------------------------------------------------------------------
