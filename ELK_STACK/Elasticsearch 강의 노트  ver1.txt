Elastic Engineer

참고 URL: 
https://elastic.co/support/eol : 제품 단종일
https://elastic.co/blog/ : 기술적 내용 공식 블로그
https://elastic.co/guide/index.html : 모든 기능
https://www.elastic.co/learn : 교육
‒ https://www.elastic.co/training : 공식 강의(유료)
‒ https://www.elastic.co/community : 공식 커뮤니티
‒ https://www.elastic.co/docs : 공식 문서
https://discuss.elastic.co
‒ https://ela.st/training-forum 

------------------------------------------------------------------
1. Elasticsearch Fundamentals
------------------------------------------------------------------
(1) 역사
1999년의 Lucene ->
    (장점) Search Engine Library(저장이 아닌 검색 엔진용) 양이 많아도 검색이 느리지 않음
    (단점) Lucene 라이브러리가 사용하기 어려움, standard-alone 기준으로 만들어서 스케일업이 어려움
2004년에 Lucene을 기반으로 한 인터페이스 솔루션 상품 제작(Compass 프로젝트)
2010년에 scalability(규모 가변적)에 대해 주요 쟁점화하여, Elasticsearch로 이름 바꿈
  - 멀티 language 지원: REST API 사용으로 Client의 언어와 무관
  - scalability 가능: cluster단위로 일함: 안에 node 몇개인지 구별할 필요가 없음
현재 검색 엔진 순위: Elastic > Splunk > Solr

(2) 개요
1) 사용 용도 : 로깅, metrics, business analytics, security analytics 등
2) ELK Stack : Beats(수집) > Logstash(수집 / 전처리) > Elasticsearch(저장 / 검색 / 분석) > Kibana(시각화)
3) 사용 방법: Standalone, Elastic Cloud Enterprise, Elastic Cloud (SaaS)

(3) 상세
1) 분산 검색 : 수평적 스케일업이 가능한 구조임 - 기본 1 to 1 (일반적으로 1개 node당 1개 서버로 사용)
              검색은 1개의 Cluster 기준으로 처리(Cluster는 1개 node 이상으로 구성[master nodes, ingest nodes, data nodes-hot, data nodes-warm])
2) JSON Objects 처리: 테이블 형태가 아닌 json object 로 사용
3) Document Store: json object 1개 - data 폴더 안에 document가 저장됨(각 document는 1개의 cluster 안에서 Unique ID 값 가짐)
4) 최초 설치 및 동작:
 - www.elastic.co/downloads/elasticsearch : 릴리즈 버전 파일(설치파일)
   https://github.com/elastic/elasticsearch : 소스 형상
 - JRE / JDK 사전 설치 필요 : JAVA_HOME에 설정(단 Elasticsearch 7.x 에서는 java도 함께 다운 로드됨, JAVA 8 필요, https://www.elastic.co/support/matrix#matrix_jvm 참고)
 - 경로 정보
   bin: 실행 파일 / plugin
   config : elasticsearch.yml 파일          : ES_PATH_CONF
   data   : 인덱스와 공유 node에 대한 데이터  : path.data
   jdk    : java vm                        : JAVA_HOME
   lib    : elk 관련 library
   logs   : 로그 파일(클러스터 명으로 생성)   : path.logs
   modules: Elasticsearch modules
   plugins: 플러그인 설치 경로 
 - 주요 configuration files:
   elasticsearch.yml - 주요 설정
   jvm.options       - heap 할당에 대한 정보 (예시: -Xms1g -Xmx1g )
   log4j.properties  - log 정보
 - properties 설정
   1) config file을 직접 수정 
   2) command line에서 수정 : ./bin/elasticsearch -E path.data=/data/elastic/elasticsearch
                             ES_JAVA_OPTS="-Xms512m" ./bin/elasticsearch
 - 동작
   1) 시작(elasticsearch 실행): 추가: ex] ./bin/elasticsearch -d -E node.name=node1 -p es.pid
                                    -d -p elastic.pid : -d (백그라운드 실행), -p (pid를 찍음[kill 할때 사용])
   2) Node : elastic instance 1개(JVM 위에 띄움), 서버 하나에 1개 노드(1-to-1 으로 불림)
   3) Node Name : unique id  자동 UUID 생성됨(node.name / .yml 파일에서 변경 가능)
                  ex) node.name: ACMEES001 [':'를 기준으로 붙이기 / 띄워쓰기 확인하기]
   4) Stop Node: Ctrl + c / kill `cat elastic.pid` 
   5) logstash 나 filebeat 실행: 
     - ./logstash-7.3.1/bin/logstash -f datasets/blogs_sql.conf
     - ./filebeat-7.3.1-linux-x86_64/filebeat -c datasets/filebeat.yml

(4) 추가 설명
 - Cluster: node 생기면 자동생성(클러스터는 노드 1개 부터 여러개 가능(노드는 1-to-1을 일반적 사용)
   cluster.name: prodcluster
 - log 파일: logs 폴더 안에 clustor 명으로 log가 찍힘 
            -rw-rw-r-- 1 elastic elastic 19267 Dec  9 01:48 elasticsearch.log					
 - Document를 하나 저장한다.(cluster)
   : cluster에 index(table과 비슷하지만 같지 않은, 논리적인 개념임[물리적 개념아님])라는 저장 공간에 파일을 indexing(document를 cluster 안에 저장하는 행위)함
 - Index a Document : Index API는 PUT / POST를 이용한다.
                      PUSH은 documentID를 찍어서 넣고, POST는 documentID를 지정하지 않고 elastic엔진지 자동 생성함
                      curl -X PUT "localhost:9200/my_blogs/_doc/1" -H 'Content-Type: application/JSON' -d
                                                 /인덱스name/document endpoint/documentID
 - Console: Kibana는 DevTools에서 테스트 해볼 수 있음
 - The Resopnse 확인 사항 
   : httpstatus : 201 response 확인
     ID: _id
	  Document: _version
 - Elasticsearch는 PUT 계속 사용시 insert후 다음번 호출시 update 함(_doc 사용시)
   : PUT my_blogs/_create/1 => 호출시 처음은 insert하고 이후 error 발생
   : _update => 호출시는 처음 insert하지 않고, 있어야지만 update함
   : DELETE my_blogs/_doc/1 : 200이면 document 삭제함
 - Bulk API: (create / index / update / delete 호출)을 1번으로 호출함
   : POST comments/_bulk
      {"index" : {"_id":3}},
	   {"update" : ... },
	   {"delete" : ...}
 - Retrieving a Document: GET my_blogs/_doc/1 - _source안이 우리가 넣어준 raw data
 - CRUD Operations:
   Index(POST/PUT은 _doc), Create(PUT은_create), Read(GET은_doc), Update(POST는_update), Delete(DELETE는_doc)
 - 엘라스틱서치에서 처리 DATA
   Dataset: Static Data vs Time Series Data 처리 - 양쪽 모두 적용 가능함
   형태 1. static Dataset: Elastic blog 글(RDBMS에 있는 것)
   형태 2. Time Series Dataset: elastic.co/blog의 access log를 이용
 - kibana는 auto refresh로 사용 가능(대시보드처럼 초단위 refresh 사용가능)
 - Search
   : queries(검색) 와 aggregations(분석 통계 지표, ex)남성이 구매한 총액 / 여성이 구매한 총액 )
 - response: quertis 는 hits
             aggregations는 buckets
      ex) GET my_blogs/_search : took는 얼마나 걸렸는지(milliseconds)
          GET logs_server1,logs_server2/_search
	       GET logs_server*/_search
 - 기본적인 검색 요청의 경우 최초 10개만 리턴함(설정으로 변경은 가능함)
 - logstash 를 실행해서 사용함
   input / filter / output을 이용함
   input {
      jdbc {
         jdbc_connection_string => "jdbc:postgresql://db_server:5432/"
         jdbc_driver_class => "org.postgresql.Driver"
         jdbc_driver_library => "/home/elastic/postgresql-9.1-901-1.jdbc4.jar"
         jdbc_user => "postgres"
         jdbc_password => "password"
         statement => "SELECT * from blogs" // 한 row가 document 화 됨
         }
      }

      filter {
         mutate {
            remove_field => ["@version", "host", "message", "@timestamp", "id", "tags"]
         }
      }

      output {
         stdout { codec => "dots"}  // 실행될때 '.'을 찍음
         elasticsearch {
            index => "blogs"
         }
      }




------------------------------------------------------------------
2. Elasticsearch Queries
------------------------------------------------------------------

(1) Query 이용 방식
 1) relevant 
  찾을것을 다 가져왔는냐(Recall)
  찾아온것 중에 내가 원한것이 얼마나 되느냐(Precision)
  => Ranking 하여 결과 도출
	ex)
	GET blogs/_search
	{
		"query": {
			"match": {
				"content": "ingest nodes"
			}
		}
	}
=> 너무 많이 나옴, ' '는 or 조건임

 2) 7.0 이상을 10000개 이상이면 relation 값이 gte로 추가되고 value는 10000이 찍힘(이하면 relation이 eq 임)
	=> "track_total_hits": true - 정확한값 필요할때
	ex)
	GET blogs/_search
	{
		"query": {
			"match": {
				"content": "ingest nodes"
				"operator": "and"
			}
		}
	}

 3) term이 3개 일때
	ex)
	GET blogs/_search
	{
		"query": {
			"match": {
				"content": "ingest nodes logstash"
			}
		}
	}
	=>
	GET blogs/_search
	{
		"query": {
			"match": {
				"content": "ingest nodes logstash",
				"minimum_should_match": 2 // 3중에 2개만 match 문서
			}
		}
	}

(2) Query 관련 용어 및 추가 설명
 - TF(term frequency) - 예를 들면 the 값은 경우는 많이 나오지만 불필요함(field 별로 계산)
 - IDF(inverse document frequency) - 짧은 문장안에서 너무 자주 나오는 단어면 중요도를 높인다.(index 전체에서 계산)
 - Field length
    => 현재 elasticSearch의 Sroce는 위를 개선하여 BM25 알고리즘 사용함 
 - match query에서 relevance 높이기 위해서는 'AND'가 무조건 사용해야하는 것은 아니다.
   precision을 높이기 위해서는 match에서 minimum_should_match를 사용한다.
   TF는 5번 넘어가면 그 다음 값은 비슷해짐(the, to 등의 전치사일 것이므로 5번 이상인 것은 제외하여 검색하는 것이 필요)
  => elastic relevance 검색 => 사용 알고리즘을 변경 할 수 있다.(script나 index 하위 similarity를 가지고 선정 할 수 있음) 
   : index-modules-similarity.html 문서를 참조한다.
   : 하지만 기존 field에 대해서는 새로 색인 해야함(신규 field는 새로 색인 안해도 됨)
     => 단 외부에서 접속할때는 alias를 이용해야 field가 변경되어도 처리 할 수 있게 해야함
 - Searching for phrases: 
   match_phrase Query
   the slop parameter - 2단어로 그물을 넓히거나 줄일 수 있음
   pre-field Boosting - 제목에서 score를 더 주게됨
    "title" -> "title^2" 로 변경함(부스트)
   boost를 잘하는 법
    - it depends(author는 큰 의미 없음)
	- 각자의 데이터에 맞는 것을 작성해야함
  "type": "phrase"로 match를 사용하지 않고, match_phrase를 사용함
  - Mispell Words : 오타 찾기
    - fuzziness를 사용 가능함 shark - shard 이면 fuzziness 1
                            matche queri - match query 이면 fuzziness 2
							=> 한글의 경우 글 1개에 대해 fuzziness(unicode 기준, 노리 등에 대해서도 쓰고 난 다음 결과로 처리함)
    - misspelling에 대해서 2개의 강의
     : 비용 존재하는 강의 존재함....

 Quiz: match(텀 상관 없이 맞춤) match_phrase(텀에 순서 등에 따라 맞춤)
       match_phrase는 slot propertity가 있어야 진행가능함
       monitoring data일때는 어떻게 될지 확인 필요(fuzziness는 auto로 생성할 수도 있음)	   


(3) 추가 쿼리
 1) The bool Query
	- Query: must(있어야함) / must_not(없어야 함) / should(있으면 좋다, hits에 영향을 대부분 주지 않지만, 특정 시점[should만 사용할때]에만 영항줌) : 점수계산이 존재함 
	- Filter: filter(must 지만 점수 계산을 안함) => 빠름

	- Improving Relevancy: 
	GET blogs/_search
	{
		"query": {
			"bool": 
				"must": [
					{"math": {"title":
	- USE minimum_should_match 사용 가능함
	- "should": [
		{match": {"title": "stack"}}.
		{"match_phrase": ...
	- Only "should" 이면 여러개중 하나만 match 되면 된다는 형태로 로직 구현됨
(4) A Search Tip for Phrases
 1) Other Ways Query method (DSL 이외에 사용)
	- query string: elastic search 에서 자동 DSL로 전환함
	ex) "query": "admin geoip.city_name:(\"san jose\") host:server1", ...
	- Kibana Query Languaget 
	- SQL Access: 실제 SQL로 쓸 수 있는 고난이도의 SQL은 작동 안함
	ex) "query": """
			SELECT * FROM blogs
			WHERE publish_date >= CAST('2018-01-01' AS DATETIME)
			LIMIT 5
		"""
 - Quiz
 1. scriptng을 찾을때 Engineering 카테고리에서만 찾으로고 할때의 Query는
    match와 filter를 bool 쿼리로 연결하기
 2. filter는 score 계산 안함
 3. title필드의 performance가 있으면 올라가는가?
 - 추가: should 등에 대한 것은 순서가 상관 없음

(5) Implementing a Search Page
 1) Filter
   Filter by a date range 사용 가능함
    - Filter와 Cache를 많이 사용할 수록 성능이좋아짐
    "filter": {
		"range": {
			"publish_date": {
				"gte": "2017-12-01",
				"lt": "2018-0-01"
			}
		}
	}	
   Date Math
    "range": {
		"publish_date":{
			"gte": "now-3M"
		}
	}
   Date Math Expressions
	if now = 2017-10-19T11:56:22
    => 날짜 기준이면 00:00:00 으로 끝남
	
   Searching for Exact Terms
    "match": {
		"category": "Brewing in Beats"
	} // OR 조건으로 3개 나옴
	"match": { "categor.keyword": "Brewing in Beats" } } // category로 저장하면 keyword 에 전처리 없는 문자열 그대로 들어감
    "filter": {
		"match": {
			"category.keyword": "Brewing in Beats"
		}
	} // 성능을 향상 시킬수 있음
	
 2) Sorting
    Soring Result
	"sort": [
		{
			"publish_date": {
				"order": "desc"
			}
		}
	]
	
	여러개 줄 수 도 있음
	"sort": [
		{
			"author.keyword": { // keyword는 꼭 사용해야 java heap에 올라가는 메모리를 줄일수 있음
				"order": "asc"
			}
		},
		{
			"publish_date": {
				"order": "desc"
			}
		}
	]
	
 3) Paging
	 // from은 0부터이고 아래 내용은 2page임(하지만 실제 운영파일에 대해서는 from을 쓰지 않는게 좋고, scroll API를 쓰는게 좋음)
	 Paging
	  {
	  "from": 10,
	  "size": 10, ...
	
	 from size가 너무 많으면(10000이 넘어서는 안됨, 설정으로 바꿀수 있으나 메모리 사용량으로 권장하지 않음) error가 발생함
	 => memory의 오버해드가 크므로, scroll에 대해서는 batch처럼 Client에서 구현하도록 하기


    실시간 Data에 대해서 paging 처리는: 
	 
 4) Highlighting
	
	"highlight": {
		"fields": {
			"title": {}
		}
	}
	
 5) 커스터마이징	
	"highlight": {
		"fields": {
			"title": {}
		},
		"pre_tags": [{"<es-hit>"],
		"post_tags": [{"</es-hit>"]
	}
	
 - Quiz
 1. paging 할때 처리는 : from, size
 2. sorted는 score로 결과 리턴하는 것만은 아니다.
 3. "category": ... / "category.keyword": ...
   -> 앞은 공백을 OR로 리턴하는데, 뒤는 keyword에 대한 필드 검색함
   
 - 문의: match term 쿼리와 keyword 사용하는 쿼리는 같은 것인지요?
       - 분석 안하기때문에 똑같은 리소스 사용하고 결과도 같음
	   highlight는 어디에 나오는지
       - 검색이 되는 컬럼에 대해서 처리 하는 경우가 있음 

------------------------------------------------------------------
3. Elasticsearch Aggregations
------------------------------------------------------------------

 - Metrics / Bucket / Combining Aggregations을 사용함(관련 내용 교육)
 
(1) Metrics Aggregations
 - 몇초만에 response time에 대해서는 얼마인지 등 질문 하나당 답변 하나가 나오게 함
  "aggs": {
	"1": {
		"sum": {
			"field": "response_size"
		}
	}
  }
 
 - Aggregation Syntax
    GET my_index/_search
	"aggs": {  // 메소드명
		"my_aggregation": {  // 변수명
			"AGG_TYPE": {
			...
			}
		}
	}
  ex) GET logs_server*/_search
		"aggs": {  // 메소드명
			"total_sum_bytes": {  // 변수명
				"sum": {
					"field": "response_size"
				}
			}
		}
	
	"aggregations": {
		"total_sum_bytes": {
			...
		}
	}
	
 - 검색이 아니라 aggregations만 쓸때는
	"size": 0 으로 하면 네트워크 점유율 낮추는 장점: Fetch 단계를 건너 뜀(_source 획득 불필요)
	"query"가 있는경우 query 실행 후 남은 결과에 대해서 aggregations 하여 처리함
	- "min", "max", "avg" 는 있지만 "median"은 없음("percentitles" 는 사용 가능)
	- 각 백분위의 값(중간 값 등을 획득 가능)
      "percentiles": {
		"field": "runtime_ms",
		"percents": [
			25,
			50,
		    75
		]
	  }
	- 유니크값 뽑기(HyperLogLog++ 알고리즘 사용, 빨리 결과가 나오지만 정확도가 떨어짐, 경향을 파악하는 경우로 사용 해야함)
	   => 유니크값을 정확히 뽑기 위해서는 별도 개발 필요
		"cardinality": {
			"field": "geoip.country_name.keyword"
		}

 - Metrics aggregations: min, max, avg, stats사용 가능함
                          percentiles의 median은 50%일때 값을 사용 가능
    - 밀리세컨즈: 1000ms = 1s


(2) Bucket Aggregation
 - Metrics Aggregation은 숫자 하나에 대한것을 리턴함
 - Bucket Aggregation는 
 - Bucket은 특정 룰에 맞춰서 document들을 저장함
 ex) "date_hostogram": {
		"field": "@timestamp", // datetime을 기준으로 생성함
		"interval": "day"      // 일별로 bucket를 만듦
	 }
 - histogram Aggregation: 숫자 타입으로 범위 지정 가능함
     "histogram": {
		...
	 }
 - range Aggregation : 범위별로 처리함
    "ranges": [
		{
			"from": 0,
			"to": 200
		},
		...
 - terms Aggregation: DOCUMENT가 많은것 부터 desc로 정렬됨(추가 sorting을 위해서는 order 옵션 추가함)
    "aggs": {
		"country_name_terms": {
			"terms": {
			"field: "geoip.country_name.keyword",
			"size": "5"
 - Bucket Aggregation:
    
 - Bucket Sorting: 
	"date_histogram": {
		"field": "@timestamp",
		"interval": "day",
			"order": {
				"_key": "desc"
			}

- Quiz
 1. 처음 버켓 사용시 dynamic 하게 변경됨
 2. 어떤 버켓 Aggregation은 일반적인 ordering을 제외한다.
 3. "error", "warn", "info", etc에 대해서는 term aggregations 을사용하면 좋다.
	"size": 0,
	"query": {
		"range": {
			"publish_date": {
				"gte": "2017-01-01",
				"lt": "2018-01-01"
			}
			...
	"aggr": {
		...
	}
 
(3) Combined Aggregation
 - 해당 날짜의 기간 등의 질문에 답할 수 있음
 - 키바나에서 Visualize > table로 생성한 다음 > inspector > request 를 보면 DSL로 표현되어 확인 할 수 있음 
 - sub-Bucket을 사용 할 수 있음: 날짜별 bucket를 만들고 terms에 aggregations 처리하기
 - Motivation for top_hits Aggregation
  -> 버켓별로 나눠서 할 수 도 있음
 - Significant Aggregation: Terms Aggregation + Noise Filter
    - 추천이나 부정행위 탐지 / 결함 탐지에 사용
   "aggs": {
		"author_buckets": {
			
     => 자주 있는 것중에 의미있는 것을 알고 싶다(in, to, the 말고)
	"significant_text": { ...}
	를 이용하면, 다른 블로거도 함께 많은 것은 제외한 결과 값을 뽑음
	  - text / keyword 에 따라서 : significant_text / significant_keyword 두가지
	   => sampler aggregation 은 특성만 확인 할때 사용함(속도 빠르고, 메모리 사용량 적음)
	      -> 정말 정확한 값을 위해서라면 scroll api를 통해서 고객이 직접 개발해야함

- Quiz
1. SLA을 만족하지 않는 날은 몇일인가(95%, 500ms 이하)
 - percentiles aggregation
2. 얼마나 많은 코드들이 requests가 날별로 발생했나
 - terms aggregation
3. 
	
- 추가: Term aggregation 으로 검색하면 여러가지가 나옴(pipeline aggregation)
       size가 0이 아니면 fatch phase[각서버에 호출한 다음 그에 대한 쿼리 결과를 리턴해 주므로] 단계를 줄일수 있으므로 성능 향상이 될 수 있음


------------------------------------------------------------------
4. Elasticsearch Text Analysis and Mappings
------------------------------------------------------------------
 - geodistance: 거리 => 가까운 호텔 찾기 등
 - geoboundbox: 영역에 대해 지정

(1) Mapping: json 형태 통신 / 루씬 기반 데이터 구조 저장됨
 - GET logs_server1/_mapping: Data 구조에 대한 설정
 - GET logs_server1/_setting: 활동에 대한 설정
 - Data type:   text - 풀 텍스트 분석에 사용
				keyword - 정확한 string 값 비교
				date(밀리 세컨즈) / date_nanos(나노세컨즈)
				byte / short / integet / long
				소수점 포함: float(32bit) / double(64bit) / half_float(단위가 작은것) / scaled_float(단위가큰것)
				boolean
				ip : 단순 스트링 아닌 단위 최적화한 값
 - Mapping 정의하기 : 최초 정의한 것을 바꿀수 없음(있으나 처음 만들때 생성하는게 좋음)
                   추가는 가능함
	PUT my_index
	{
		"mappings": {
			define mappings here
		}
	}
 - dynamic Mapping 지원함(document 넣을때 elastic search가 만들어 줌): field 명이나 type 값을 넣음
    - 2010-04-23T15:48:50 / 2010-04-23 등 json document의 표준 date type을 넣어주면 자동 date 로 인지함
    ex) 사용자가 지정해서 할것(금액은 scaled_float을 이용하기, 하지만 추가 소수점은못넣게 됨은 유의)
        PUT my_index/_doc
		{
		"status_code": 404
		}
		=> long type으로 들어가므로, 사용자가 지정해야 효율적 사용 가능
		{
			"logs_server1" : {
				"mappings" : {
					"properties" : {
						[...]
						"status_code" : {
							"type" : "long"
							}
						[...]
					}
				}
			}
		}
 - 왜 mappings을 다시 정의 못할까?
    - 이미 저장된 document에 대한 처리가 필요하므로, 풀 색인되는 개념이므로, 정의 못하고 추가만 가능하도록 함
 - Type 은 사라짐
    - 7.0에서는 deprecated 했고, 8.0에서는 없앰
    ex) 인덱스는 1개로 해서 필드명만 다르게 해서 넣을때 author / month 에 대해서 추가로 mapping이 생기면서 안쓰는 null 값이 많아지는 이슈
        library/book/1
        library/magazin/1
		- book : title / pages / author
		- magazin : title / pages / month
		=> 이때 book을 넣을때 month는 빈값으로 억지로 들어 가야하는 case 등이 발생하여 저장이 더 많이 됨
 - Mappings은 elk에서 data schema 를 의미함
   Mapping은 index에 정의되어 있음
   dynamic 하게 type 생성하는 것(숫자면 long으로 자동잡음)
   정의된 것을 다시 정의 할 수 없음

(2) Text and Keyword Strings
 - 풀텍스트 검색을 지원함(한국어, 전문 검색)
 - Analyzers: Elasticsearch에서 fulltext 처리를 위한것
          - standard(기본), whitespace, stop, pattern, language-specific analyzers, and more are described in the docs at
            https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-analyzers.html
		  - 텍스트 type에서만 사용 가능(숫자 등의 다른 타입에서는 사용 불가)
		  - 대문자가 소문자로, 다중 단어는 token으로 짤라서 저장함 
		     => 검색에는 좋지만 집계에는 문제가 있음
			 => 그래서 keyword field는 aggregation, sorting, exact searches 를 위해 사용하고, 통계등을 낼때 사용함
	ex)
	{
		"my_blogs" : {
			"mappings" : {
			"properties" : {
			...
			"content" : {
			"type" : "text",
			"analyzer": "english"
			}
		...
	}
	ex) _analyze 를 테스트
	GET _analyze
	{
		"text": "United Kingdom",
		"analyzer": "standard"
	}

	GET _analyze
	{
		"text": "United States of America",
		"analyzer": "english"
	}
	=> 영어 불용어(전치사) 제거 하여 검색함
 - Multi-Field
	필드는 하나라도 여러개의 속성 부여 가능
	full-text search면서 sorting, aggregating이 필요할때 text, keyword를 함께 저장함
	ex) 
	PUT my_index/_doc/20
		{
			"country_name": "United States"  -> united / states
		}
											-> keyword는 United States
											
	{
		"my_index" : {
			"mappings" : {
				"properties" : {
				...
				"country_name" : {
					"type" : "text",
					"fields" : {
						"keyword" : {
							"type" : "keyword",
							"ignore_above" : 256   // keyword가 256자 이상인 경우에는 keyword 저장하지 않음
						}
					}
				}
				...
				}
			}
		}
	}
 - Text / keyword를 모두 저장해야 하는지?
	- default로 string이 들어오면 둘다 저장함
	- 하지만 한개만 지정해서 최적화 하는게 좋음
	ex)
	PUT my_logs
	{
		"mappings": {
			"properties": {
				"message": {
					"type": "text"
				},
				"http_version": {
					"type": "keyword"
				},
				"country_name": {
					"type": "text",
					"fields": {
						"keyword": {
							"type": "keyword",
							"ignore_above": 256
						}
					}
				}
			}
		}
	}
	-> 추가 예시: 다국어 쓸때 아래와 같이 사용 가능함
	content: {
		type: text,
		fields: {
			korean: {
				type: text,
				analyzer: nori
			},
			china: {
				type: text,
				analyzer: cn
			}
		}
	}

- Quiz; 
 1. text search에서는(analyzer: standard) case-sensitive(대/소문자 구분) 안함
 2. dynamically mapped에서는 text / keyword 두개가 기본 생김
 3. keyword는 aggregation에서는 좋은 성능

(3) Inverted Index 와 Segment
 1) Inverted Index
 - 저장시 document 번호를 임의 지정하여 저장하고, 검색시 해당 숫자로 검색함
 - text가 tokens 으로 쪼개짐 > 소문자화 > sorted list로 만듬 > documentID를 함께 저장함
 - 한계점: text 필드 sorting은 가능하나 keyword sorting은 할 수 없음
	ex)
	1) Jurassic Park
	2) Avengers Infinity War
	- text: asc: 2 > 1 / desc: 1 > 2
	- keyword : asc: 2 > 1 (J와 A 비교) / desc: 2 > 1 (W와 P 비교)
 - Lucene builds multiple data structures out of your documents: inverted indices and doc values
	• The inverted index make searching fast
	• Doc values allow you to aggregate and sort on values
	• You can disable the inverted index or doc values for
	individual fields in the mapping, to optimize Elasticsearch
 2) Segment
	_source      Inverted Index
	ngram        Doc Value
	deleted Doc                 -> 빼고 쿼리함(디스크는 그대로 있고, segment 병합시에 그때 빼고 저장함)
	
- Quiz
 1. keyword 대신 text 필드로 sorting 하면 안된다.
 2. index를 false로 지정하면 inverted Index로 만들지 않음
 3. "enabled":false 해도 _source에서는 제거하지 않음(analyzer로 들어온 것은 별도 삭제 되지 않음)
 
 
(4) Custom Mappings
 - Mapping Type
	- https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.html
 - date인 경우 ISO8601이 아닌 경우 format은 지정해야함
	- https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html
	"properties": {
		"last_viewed" : {
			"type": "date_nanos",
			"format": "strict_date_optional_time"
		},
		"comment_time" : {
			"type": "date",
			"format" : "dd/MM/yyyy||epoch_millis" => epoch_millis - 특정 년도부터 숫자로 long type을 처리한 것(내부 적으로는 epoch_millis로 저장함[소스값은 그대로], IP나 range 등 범용적으로 사용할수 있도록 내부에 저장함)
		}
	}
 - copy_to Parameter로 할수 있음
 => 소스에는 없지만 mapping에만 있어서 검색이 함께 됨
 - Null Values
	PUT ratings/_doc/1
	{
		"rating": null
	}
	PUT ratings/_doc/2
	{
		"rating": 5.0
	}
 - Summary
	• Mapping parameters allow you to influence how Elasticsearch will index the fields in your documents
	• Dynamic templates make it easier to set up your own mappings by defining defaults for fields, based on their JSON type, name or path
 - IP와 Text type은 multi로 지정할 수 없음

	# 들어가는지 확인하기
	GET _cat/indices

	# index의 data 재색인 하기
	POST _reindex
	{
		"source": {
			"index": "logs_server1"
		},
		"dest": {
			"index": "logs_fixed"
		}
	}

	# 쉽게 하기 예시 값 넣고
	PUT surveys_temp/_doc/1
	{
		"instructor_feedback": "She was great!",
		"labs_feedback": "Labs were hard"
	}

	# data 확인해서 mapping값을 가지고 
	GET surveys_temp

	# 설정값 지정하기
	PUT surveys
	{
		"mappings": {
			"properties": {
				"all_feedback": {
					"type": "text"
				},
				"instructor_feedback": {
					"type": "text",
					"copy_to": "all_feedback"
				},
				"labs_feedback": {
					"type": "text",
					"copy_to": "all_feedback"
				},
				"course_rating": {
					"type": "integer",
					"null_value": 1,
					"coerce": false
				}
			}
		}
	}

- Quiz
1. format을 통해서 mapping parameter를 바꿀 수 있다.
2. copy_to로는 _source에는 바뀌지 않는 값으로 저장되어 있다.

- 추가 정리:
	GET my_test/_search
	{
		"query": {
			"range": {
				"number": {
					"gte": 3.9,
					"lte": 4.7
				}
			}
		}
	}

	GET my_test/_search
	{
	"query": {
		"range": {
		"number": {
			"gte": 4.2,
			"lte": 4.7
		}
		}
	}
	}

	PUT my_test/_doc/1
	{
	"number": 4.5
	}

	PUT my_test
	{
	"mappings": {
		"properties": {
		"number": {
			"type": "integer"
		}
		}
	}
	}
------------------------------------------------------------------
5. Elasticsearch Nodes and Shards
------------------------------------------------------------------

(1) 통신: HTTP(REST API, 사용자와 통신) vs Transport(소켓통신, node들 간의 통신)
 - HTTP: 최초 http.host로 localhost 로만 연결됨(내부 통신, 외부에 사용하려면  별도 설정 필요)
             http.port로 기본 9200 ~ 9299로 연결됨(여러 노드 띄울때는 지정하는게 좋음)
 - Transport: transport.host 최초 localhost로 바인딩함
             transport.tcp.port: 9300 - 9399
 - 방화벽 내부로 연결할때
	transport.* specify settings for the transport protocol
	http.* specify settings for the http protocol
	network.* specify settings for both protocols in one setting
 - 방화벽 사용할때(밖에서 올때)
	*.bind_host interface to bind the specified protocol to
	*.publish_host interface used to advertise for other nodes to connect to
	*.host specify both bind and publish in one setting
 - 특수값들: _local_: 서버안에서만 사용 ex) 127.0.0.1
			_site_ : 조직 안에서만 사용 
			_global_: 전체 대역 전체
			_[networkInterface]_: 네트워크 지정 대역 ex)_en0_
			=> 하지만 정확히 값 지정하는 것이 좋음
(2) 설정 값 확인
 - Discovery Module: 7.0 이상 버전부터 Seed hosts 목록에서 찾아서 마스터와 연결하는 구조 
                   : 연결 못하게 되면 cluster를 별도로 시작함
    - elasticSearch.yml에 값 입력 가능: discovery.seed_hosts: ["server1", "server2", "server3"]
    - 직접 입력:  discovery.seed_providers: file
		server1
		server2
		server3
	- plugins에서 적용가능
 - Cluster State: 모든 노드가 공유함, 클러스터 상태값 확인
	- cluster, indices, mappings, settings, shard allocation 등
	ex) GET _cluster/state
 - master의 cluster내용이 복제가 되는 것임
 - Master Node: 노드 추가 / 제거, CUD(create, update, delete)에 대해서도 결정하여 전파함 
  => Master-eligible Nodes 둥에서 하나가 됨( node.master:true로 설정해야 마스터 가능함)
     master-eligible Node끼리 투표함(N/2 + 1, 가반수 이상이면 지정됨)
	 master-eligible Node는 3으로 지정하는것을 권장했음(6.x 이하 버전), 이후 버전에서는 홀수로 자동 지정함
	  -> "split brain" 이슈 해결함
     Master Node가 죽었다가 살아나면, 다시 master node가 되지 않고 master-eligible node로 지정됨
	 Zone이 나뉘어야 이슈대응이 가능함 => zone이 총 3개가 필요함
	 node.master와 node.voting_only가 true로 지정되어야 함
 - Voting Only Nodes: 2개면 1개, (가능하면 신경쓰지 않아도 됨
	- 최초 실행할때만 참고함
	cluster.initial_master_nodes: ["node1", "node2", "node3"]

 - 사용 방법: 
    # 클러스터의 정보를 알 수 있음
	GET _cluster/state 
	GET _cat/nodes?v
	kill로 기본적으로 실행함(kill -9 [pid] 로 하지 않음)


	# 설정값 바꿀것들(elasticsearch.yml내에 설정 파일)
	cluster.name: my_cluster
	node.name: node3
	network.host: _site_
	cluster.initial_master_nodes: ["node1"]
	discovery.seed_hosts: ["server1", "server2", "server3"]

	#master 설정 후 키바나 실행(키바나는 백그라운드 실행은 nohup이나 node js 내의 src/cli/index.js  실행 파일로 정확히 맞게 실행해야함, package.json 내의 node 버전과 완전히 같아야 함[nvm package 사용 nvm use 10.15.2 > node src/cli/index.js로 실행])
	./kibana-7.3.1-linux-x86_64/bin/kibana --elasticsearch.hosts="http://server1:9200" --host=0.0.0.0  

	# 노드 확인
	GET _cat/nodes?v&s=name

	ip         heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
	172.18.0.2           32          97  11    0.69    0.34     0.29 dim       *      node-1
	172.18.0.3           22          97  13    0.69    0.34     0.29 dim       -      node2
	172.18.0.4           19          97  63    0.69    0.34     0.29 dim       -      node3
		


- Quiz: 
1. 새로 조인하는 경우: discovery.seed_hosts 사용
2. cluster 최처 등록시 설정값사용
3. 모든 Elasticsearch cluster는 짝수여야 한다(홀수여야함, 3개면 가능)

(3) Node Roles
	‒ master-eligible
	‒ data
	‒ ingest
	‒ machine learning (Gold/Platinum License)
 1) Data Node
	: data 저장 / 실행과 관련되어 있다.
	Configuring Node Roles
		Node type Configuration parameter Default value
		master eligible nod지정함e.master true
		data node.data true
		ingest node.ingest true
		achine learning node.ml true
 2) Ingest Node(하드웨어 비용만 추가됨)
	: 클라우드에서 바로 쓸 수 있다.
	: node.ingest property로 설정 가능함
	: ingest node를 추가하여 indexing 요청, query 요청함
 3) Machine Learning Nodes: ML 작업에 돌게됨, API 요청으로 사용, node.ml에 설정파일 조정함
 4) Coordnation Node: 요청 받을때 Coordinating Node로 지정되고, 나머지 node에 호출함
  -> aggregetion이 가장 어려움(coordnation node가 out of memory 될 가능성 있음)
     data node에 바로 요청하기 보다는 부하분산됨
 5) Sniffing: 동적으로 목록 관리
 6) 샘플 Arch:
    1-Node Clusters, 2-Node Clusters(2개라도 HA 되지 않음)
    3-5 Node Cluster(가장 기본이 되고, 권장하는 Arch.)
	Larget Clusters(7개 이상인 경우 지정함) - .yml 파일에 적절히 설정하기
		   
- Quiz: 
 1. delicated data node는 어디서 설정하는가? node.
 2. 2 Node는 사용 하지 않음

(4) Shards
 - Primary 최초 생성
	Replica 복제본
	=> Replica는 Primary가 있는 node 이외에 생성
 - node가 1개이면 Replica가 생성되지 않음(default 1개만 Replica 생성됨)
 - mappings 에는 data 구조, settings에는 동작에 대한 설정값이 들어가 있음
	PUT my_new_index
	{
		"settings": {
			"number_of_shards": 3,
			"number_of_replicas": 2
		}
	}
	=> shard는 9개가 됨(node가 1개인 상태라면 Replica가 1개만 추가되어 총 6개 shard 됨)
	elastic search 7.x 부터는 shard 갯수를 1개로 바꿈(shard 1개당 10GB 정도면 적당함)
 - Replica 사용 이유
  1) 고가용성을 위해 사용
    Node 1이 죽으면 남은것중에 Primary가 되고, 다시 Node 1이 살아나도 Replica가 됨
  2) 읽을때 취사선택이 가능해짐: Client가 많은때 유용함(ex. 쇼핑몰 등)

 - Cluster Health and Shard Allocation
	GET _cluster/health
	-> status 에서 red, yellow, green 을 확인(shard health는 red(index 없음), yellow(Replica 있음), green(모두 잘 살아 있다))
	- Shard Allocation: UNASSIGNED(인덱스 만들때 샤드 정보 배치전, 찰나)
						INITIALIZING(Primary 샤드들이 생성되는 상태)
						STARTED(정상적인 상태, P0이 R0을 만들고 있는 상태 부터 모두 정상인 상태) => 모두 정상이 되면 cluster가 green 됨
						RELOCATING(node가 추가되어 P0, R0이 이동되는 상태, 복사 후 삭제) => 이때는 cluster는 green
    - Shard Promotion: P0가 삭제되는 경우 R0이 P0으로 승격됨(1분안에 node가 안뜨게 되면 RELOCATING이 발생함, 그러므로 패치 작업인 경우에는 RELOCATING이 되지않도록 설정 후 작업해야함)
    - More Replicas: 기본적으로 2개씩 작업함(운영 작업상태 가정하므로), 설정으로 여러개 한번에 옮기게 할 수 있음
 - 여러개의 자료로 자르는데 이를 shard 라고 함
 - shard copy는 primary / replicas가 있음
 - cluster health가 있음
 - 사용 방법
 	GET _cat 를 하면 _cat의 추가 명령어가 다 보임
	GET _cluster/state
	GET _cat/nodes?v
	GET _cat/nodes?v&s=name
	GET blogs/_search
	GET blogs/_doc/Eg_V6G4BNE0WxPmPKzl7
	GET _cat
	GET /_cat/allocation
	GET /_cat/shards/logs_server2
	GET _cluster/health
	PUT test1
	{
		"settings": {
			"number_of_shards": 4,
			"number_of_replicas": 2
		}
	}
	GET test1
	GET _cat/shards/test1
	PUT test1/_settings
	{
		"number_of_shards": 1
	}
	PUT test1/_settings
	{
		"number_of_replicas": 1
	}



- Quiz
 1. number_of_shards 5, number_of_replicas 2면 총 12개 shards 임

- 추가: 노드수가 부족하거나, 노드에 80% 디스크 스페이스 넘을때, attribute로 특정 node에 replica 하도록 할때에 갯수가 맞지 않을 수 있음
       elasticsearch는 전체 disk에서 85% 이상이 차있다면(다른 것들이더라도) 해당 노드로 relocation 되지 않음


(5) Distributed Operations
 - PUT blog/_doc/551(routing number)
 => 어떤 shard에 들어가 있는지 알 수 없음
   - shard = hash(_routing) % number_of_primary_shards 로 shard 결정함
    아래 두개는 다른 동작함
     GET blogs/_search : 중간 단계존재하여 검색함, 샤드가 어디갈지 결정해야하는 작업이 존재(Inverted Index를 바라보고 검색하기 때문에 느림)
     GET blogs/_doc/Eg_V6G4BNE0WxPmPKzl7 : 샤드로 바로 가서 검색해옴(성능 향상)
   - 내부 작업 순서: coorination Node로 명령 전달 > 샤드 계산한 node 로 명령 전달 > replica를 node에 작성 > 성공을 리턴하여 최종 coorination에서 client에 success 리턴함
 - Update / Delete : _update는 insert 후 delete 하는 작업임
 - refresh가 발생한 후 검색이 됨(default 1초), segment를 1초마다 만든다. 그 이전으로 하면 문제 발생함, refresh_interval을 늘리면 색인 속도가 들어남(단, GET은 바로 됨, Inverted Index를 사용하지 않으므로)
         : refresh=wait_for - inverted index 응답이 검색 가능한 상태일때 옮
		   refresh=true - 넣을때 강제로 refresh 시킴
 - 예시: PUT Index/_doc/1 이면 buffer에 저장 먼저되고 이후 refresh에 segment에 작성됨
        이후 PUT을 5까지 하고, 이후에 Delete 2, 5가 오게되면 Segment Merge 단계에서 1,3,4의 Segment 로 병합하여 만듦
		=> near real time 검색
 - 검색의 동작 원리 : Client가 search 함 >  coordinating node에서 각 shard(cluster state에서 shard 위치 확인)에 검색 요청 > The Query Phase(여러 노드의 1개(replica 또는 primary)씩에 다 검색함) > 결과를 coordinating node에 리턴함 > Fetch 단계[실제 값이 있는 node에 data를 달라고 요청함] > 실제 값(source)을 리턴됨
                   => size를 0으로 하면 fetch 단계가 없어 빠름(document정보에서만 필요한 경우 aggregation에서 사용)
 - 실행 예시
	PUT my_refresh_test1
	{
		"settings": {
			"refresh_interval": "1h"
		}
	}
	PUT my_refresh_test1/_bulk
	{ "index" : { "_id" : "1"}}
	{ "level" : "test"}
	{ "index" : { "_id" : "2"}}
	{ "level" : "test"}
	{ "index" : { "_id" : "3"}}
	{ "level" : "test"}
	GET my_refresh_test1/_search
	GET my_refresh_test1/_doc/1
	POST my_refresh_test1/_refresh => 강제 refresh
	POST my_refresh_rest/_forcemerge => 날짜단위로 지우는 것을 추천하지만, 안되면 밤에 이렇게 지우는 게 좋음(Disk IO가 있어서 운영중에는 하지 않는 것을추천함)
										- Log는 날짜 단위로 지우는게 좋음
										- ex) static인 경우는 스테이징 서버에서 한 다음 주기적으로 운영서버에 부어 버림
	# 삭제후 직접 ID로 검색하면 data는 검색이 가능함, 이후 삭제가 됨
	하지만 삭제한 것을 살릴방법은 없음(살려도 정상적으로 동작하도록 처리하게 하기 어려움)
	elasticsearch를 넣기만 잘하면 이후 작업은 문제없이 동작가능함: 전체 Project의 50% 잡을만 함
	DELETE my_refresh_test1/_doc/2
	GET my_refresh_test1/_doc/2

- Quiz
 1. True : An index operation has to be executed on the primary shard first before being synced to replicas.
 2. True o: After an index operation documents might not be searchable up to 1 second.
 3. What happens if you use ?refresh=wait_for in an index request. Explain one use case that benefits from it? => refresh 단계 끝나고 리턴됨

------------------------------------------------------------------
6. Elasticsearch Monitoring and Troubleshooting
------------------------------------------------------------------
(1) HTTP Response and Shard Allocation Issues
 - Response : HTTP status code return 함
 4xx -> 요청의 잘못(query 보기)
 429 -> 요청은 정상이지만 동작할수 없을때(retry 하면됨), ELK를 쓰면 bits 나 logstash는 해당 error code면 멈췄다가 다시 동작하는 알고리즘이 동작함
 5xx -> 시스템의 잘못(서버 로그 보기)

 - Index Response Body
	"_shards": {
		"total": 2,
		"successful": 2,
		"failed": 0
	},
	=> 모두 정상적일때
	"_shards": {
		"total": 2,
		"successful": 1,
		"failed": 0
	},
	=> 1개만 유용할때(아직 정상)
	"_shards": {
		"total": 2,
		"successful": 1,
		"failed": 1,
		"failures": [
			{
			"_index": "test",
			"_shard": 0,
			"_node": "-mz8qioOQk-sIx9X4A3w_w",
			"reason": {
			"type": "node_disconnected_exception",
			"reason": "[node3][172.18.0.4:9300]
			[indices:data/write/bulk[s][r]] disconnected"
			},
		"status": "INTERNAL_SERVER_ERROR",
		"primary": false
	}
	=> 1개 실패이고, 실패 원인 전달
	"_shards": {
		"total": 47,
		"successful": 47,
		"skipped": 0, // elasticsearch가 임의 지정하여 불필요 shard 있을때 값 존재(거의 없음)
		"failed": 0
	},
 - error 상세
	PUT test1/_doc/
	{
	"test": "test"
	}
	=> 405 error 발생함(POST를 쓰면자동 ID 생성)

	GET blogs/_search
	{
	"query": {
		"match" : {
		"title": "open source software",
		"minimum_should_match": 2
		}
	}
	}
	=> 404 error라서 아래와 같이 호출해야함
	GET blogs/_search
	{
	"query": {
		"match" : {
		"title": {
			"query": "open source software",
			"minimum_should_match": 2
		}
		}
	}
	}

	GET blogs/_search
	{"query":{"match":{"title":{"query":"open source software,"minimum_should_match":2}}}}
	=> 500error 로 파싱 에러
	GET blogs/_search
	{"query":
	{"match":
		{"title":
		{"query":"open source software","minimum_should_match":2
		}
		}
	}
	}

	data 폴더 내에 GET _cat/indices 에나온 값이 폴더 명으로 data가 저장 됨

 - cluster health
    GET _cluster/health?wait_for_status=yellow -> red에서 yellow가 될때 리턴해달라는 명령어
	GET _cluster/health/my_index => 특정 인덱스에 대해서만 나올 수 있음
	GET _cluster/health?level=shards => shards의 갯수만큼 나옴
    : 클러스터 상태 값에 대해서 확인하기
	  클러스터의 순서등에 대해서만 알고 있으면 됨
	  모든 읽기와 쓰기에 대해서는 모든 shard에서 동작했는지 리턴해줌

- Quiz
 1. _shards 섹션은 내 명령이 잘 되었는지 확인하기 위해 필요가
 2. UNASSIGNED는
 3. skipped은 Elasticsearch가 지혜롭게 건너뛴 것

(2) Kibana Monitoring
 - Kibana에 Monitoring 할 수 있음(xpack.monitoring.collection.enabled defaults to false)
	- 수집 주기(default 10초)등 설정
 - xpack.monitoring.collection.indices The indices to collect data from. Defaults to all indices, but can be a comma-separated list.
 - xpack.monitoring.collection.interval How often data samples are collected. Defaults to 10s
 - xpack.monitoring.exporters Configures where the agent stores monitoring data. By default, the agent uses a local exporter that indexes monitoring data on the cluster where it is installed.

 - dedicated cluster를 사용할 수 있고 security 정책을 지정할 수도 있음(과금시에도 1개의 monitoring_cluster는 과금 하지 않지만, 2개 이상의 node가되면 과금됨, 무료일때는 상관 없음)
  xpack.monitoring.exporters:
   id1:
   type: http
   host: ["http://monitoring_cluster:9200"]
   auth.username: username
   auth.password: changeme

 - GOLD / PLATINUM이면 여러개의 Product를 하나의 monitoring에서 볼 수 있음
 - 4개에 대해서 등록하여 쓸 수 있음(ELK + Bits)
   dedicated cluster를 사용하는 것이 좋다.

- Quiz
 1. Elastic Monitoring은 라이선스가 있어야 여러개의 clusters를 모니터링 할 수 있다.
 2. 
 3. Monitoring Collection은 기본 10초

--------------------

(3) Diagnosing Performance Issues
 - GET _cat/nodes
 - GET _cat/nodes?help
 - GET _cluster/pending_tasks : 실행중인 목록만 나옴(오래 실행 되는것으로 확인함)
 - GET _tasks
 - curl -i -H "X-Opaque-Id: 123456" http://server1:9200/_tasks : 작업을 추적 할 수 있음
 - 큐에 쌓인것 확인 (GET _nodes/thread_pool  /  GET _nodes/stats/thread_pool) : 1분마다 호출해서 줄어드는 것을 확인하기 가능
 - GET _cat/thread_pool?v : bulk indexing은 꽉차도 문제 없지만(429 status Code를 확인하여 logstash / bits는 기다림), search queue는 꽉차면 검색이 되지 않으므로 문제가 됨
 - hot threads API: GET _nodes/hot_threads  / GET _nodes/node1/hot_threads
  => 파일 저장 후 grep 'cpu hot_threads | sort usage' 로도 처리 할 수 있음(단, 9.9 / 99.9 도 같이 나오긴 하지만 구별됨)
 - Slow log로 확인 가능
	PUT my_index/_settings
	{
		"index.indexing.slowlog" : {
			"threshold.index" : {
				"warn" : "10s",
				"info" : "5s",
				"debug" : "2s",
				"trace" : "0s"
			},
			"level" : "trace",
			"source" : 1000
		}
	}

	PUT my_index/_settings
	{
		"index.search.slowlog": {
			"threshold": {
				"query": {
					"info": "5s"
				},
				"fetch": {
					"info": "800ms"
				}
			},
			"level": "info"
		}
	}
 - Search Profiler에서 확인도 가능함(kibana에서 search profile 탭에서 확인 가능)
	GET logs_server*/_search
	{
		"size": 0,
		"profile": "true",
		"aggs": {
			"top_cities": {
				"terms": {
					"field": "geoip.city_name.keyword",
					"size": 20
				},
				"aggs": {
					"top_urls": {
						"significant_text": {
							"field": "originalUrl.keyword",
							"size": 3
						}
					}
				}
			}
		}
	}
 - Circuit Breakers: OutOfMemoryError 전에 미리 에러 발생(node는 죽지 않음), 메모리가 해당 node에 부족하므로, 조치는 해야함(쿼리 경량화 또는 노드 추가 등)
	‒ parent circuit breaker
	‒ field data circuit breaker
	‒ request circuit breaker
	‒ in flight requests circuit breaker
	‒ accounting requests circuit breaker
	‒ script compilation circuit breaker // 다른것과 달리 컴파일시 너무 많은 스크립트를 쓰는 것을 막을때 발생(3분에 x 개 이상일 경우) => stored script를 사용하면 이슈 없음
 - 부하 주면서 그때 task 확인하기
	# 부하주기
	POST _reindex?wait_for_completion=false
	{
		"source": {
			"index": "logs_server*"
		},
		"dest": {
			"index": "logs_test4"
		}
	}

	# 작업 내용 확인
	GET _tasks
	GET _tasks?actions=*reindex
	GET _tasks?actions=*reindex&detailed
	GET _tasks/UsXrD5lESuWbf5Df5f3fiA:8496

- Quiz
 1. 
 2. "profile"을 ture로 처리하거나 kibana로 확인할수 있다
 3. circuit breaker는 서버의 OutOfMemoryError 전에 발생함
- 추가 : hot / warm / cold 아키텍쳐인 경우 cold에서는 많이 작업이 이루어 지지 않도록 설계해야함(cold는 쿼리만 하기 또는 hot이 같은 ssd면 더 작은 용량으로 하기[용량이 적어야 관리 data가 적으므로] 등)
        사이징은 https://www.elastic.co/kr/blog/how-many-shards-should-i-have-in-my-elasticsearch-cluster 를 본다.
	            샤드 갯수가 노드 갯수의 배수가 되는 것이 좋다.(불균형이 발생하지 않도록, 특히 큰 인덱스가 있을때 노드갯수가 맞지 않으면 발생할 가능성 많음)
	            샤드 갯수로 나눠서 Data를 넣기 때문에 하나의 node에서 큰 용량의 샤드에 대해서는 추가 data을 못넣게 하는 경우도 있으니, index 를 정리해야 함
        Primary는 default가 1로 바꾼것은 샤드가 많을수록 기본 오류가 많아서임
        일시적 노드를 추가 하는 경우에 대해서는 정리 후 빼는 것 정도는 과금없이 가능함(upgrade 할때도 비슷함)	   